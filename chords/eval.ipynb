{
 "metadata": {
  "name": "",
  "signature": "sha256:353d1978169c4a4cc0243988158ecbab7451a5fbb16b46a73dbde9712c6a1294"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Automatic Chord Estimation - Evaluation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Visualization code accompanying Chapter 5"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Imports and config\n",
      "from collections import OrderedDict\n",
      "import glob\n",
      "import json\n",
      "import mir_eval\n",
      "import numpy as np\n",
      "import pyjams\n",
      "import tabulate\n",
      "\n",
      "# Viz\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "import mpld3\n",
      "import seaborn\n",
      "seaborn.set()\n",
      "mpld3.enable_notebook()\n",
      "np.set_printoptions(precision=4)\n",
      "\n",
      "# DL4MIR stuff\n",
      "import dl4mir.common.util as util\n",
      "import dl4mir.chords.lexicon as lex\n",
      "import dl4mir.chords.evaluate as E\n",
      "\n",
      "# Path variables\n",
      "basedir = \"/Volumes/megatron/dl4mir/chord_estimation\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Partitioning the Reference Annotations"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Based on previous findings in chord estimation research, the neural networks were trained exclusively on strictly filtered chord labels rather than attempt to shoe-horn these other chord labels into a fixed number of classes.\n",
      "\n",
      "For the purposes of evaluation, it will be necessary to consider the networks perform in three different scenarios:\n",
      "* Only on **strict** chord labels\n",
      "* Only on **other** chord labels\n",
      "* Only **all** chord labels\n",
      "\n",
      "First, it will be necessary to split the reference annotations into these subsets."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "refs = util.load_jamset(\"{basedir}/references_all.jamset\".format(basedir=basedir))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_key = refs.keys()[0]\n",
      "jam = refs[test_key]\n",
      "annot = jam.chord[0]\n",
      "print annot.labels.value[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'N', u'D:min7', u'Db:9(b5)', u'C:maj', u'G:maj/3', u'F:maj/3', u'C:maj/5', u'F:maj7', u'C:maj/3', u'D:7']\n"
       ]
      }
     ],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print jam.file_metadata"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{\n",
        "  \"duration\": 338.85995, \n",
        "  \"title\": \"Piano Man\", \n",
        "  \"identifiers\": {\n",
        "    \"audio_md5\": \"2f13b45e3e65530ca3d51f3545a58d58\", \n",
        "    \"echonest_track_id\": \"TRLMOYB127F8B4D8B9\", \n",
        "    \"md5\": \"6fd68264d9230baed9fe5a98cb11c819\"\n",
        "  }, \n",
        "  \"jams_version\": \"0.0.1\", \n",
        "  \"artist\": \"Joel, Billy\"\n",
        "}\n"
       ]
      }
     ],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vocab = lex.Strict(157)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Iterate over the reference set, and \"turn off\" labels that \n",
      "# *are not* strictly in the class prediction space.\n",
      "strict = dict()\n",
      "for key, jam in refs.iteritems():\n",
      "    strict[key] = pyjams.JAMS(**jam)\n",
      "    for annot in strict[key].chord:\n",
      "        gamut = E.v157_strict(annot.labels.value, annot.labels.value)\n",
      "        for idx, value in enumerate(gamut):\n",
      "            if value < 0:\n",
      "                annot.data[idx].label.value = \"X\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 75
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "jam = strict[test_key]\n",
      "annot = jam.chord[0]\n",
      "print annot.labels.value[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'N', u'D:min7', 'X', u'C:maj', 'X', 'X', 'X', u'F:maj7', 'X', u'D:7']\n"
       ]
      }
     ],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "util.save_jamset(\n",
      "    strict, \n",
      "    \"{basedir}/references_strict.jamset\".format(basedir=basedir))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Iterate over the reference set, and \"turn off\" labels that *are*\n",
      "# in the class prediction space.\n",
      "others = dict()\n",
      "for key, jam in refs.iteritems():\n",
      "    others[key] = pyjams.JAMS(**jam)\n",
      "    for annot in others[key].chord:\n",
      "        for idx, obs in enumerate(annot.data):\n",
      "            if not vocab.label_to_index(obs.label.value) is None:\n",
      "                obs.label.value = \"X\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "jam = others.values()[0]\n",
      "annot = jam.chord[0]\n",
      "print annot.labels.value[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['X', 'X', u'Db:9(b5)', 'X', u'G:maj/3', u'F:maj/3', u'C:maj/5', 'X', u'C:maj/3', 'X']\n"
       ]
      }
     ],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "util.save_jamset(\n",
      "    others, \n",
      "    \"{basedir}/references_others.jamset\".format(basedir=basedir))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Pulling in Results"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res_fmt = \"{basedir}/results/{model}/{dropout}/{fold}/{split}/{partition}.json\"\n",
      "models = [\"L\", \"XL\", \"XXL\"]\n",
      "dropout = [\"0.0\", \"0.125\", \"0.25\", \"0.5\"]\n",
      "folds = range(5)\n",
      "splits = ['train', 'valid', 'test']\n",
      "partitions = ['all', 'strict', 'other']\n",
      "metrics = ['triads', 'root', 'v157_strict', 'mirex', \n",
      "           'tetrads', 'sevenths', 'thirds', 'majmin']\n",
      "# Sorted by occurence in the data\n",
      "quals = ['C:maj', 'C:min', 'C:7', 'C:min7', 'N', 'C:maj7', 'C:maj6',\n",
      "         'C:sus4', 'C:sus2', 'C:aug', 'C:dim', 'C:min6','C:hdim7', 'C:dim7']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "params = dict(\n",
      "    basedir=basedir, model=models[2], dropout=dropout[0],\n",
      "    fold=folds[0], split=splits[2], partition=partitions[1])\n",
      "res = json.load(open(res_fmt.format(**params)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Collect deep network scores (EJH)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "macro_aves = np.zeros([3, 3, 4, 5])\n",
      "micro_recall = np.zeros([3, 3, 4, 5, 8])\n",
      "qualitywise = np.zeros([3, 3, 4, 14, 2, 5])\n",
      "for si, s in enumerate(splits):\n",
      "    for mi, m in enumerate(models):\n",
      "        for di, d in enumerate(dropout):\n",
      "            for fi, f in enumerate(folds):\n",
      "                res = json.load(open(res_fmt.format(\n",
      "                    basedir=basedir, model=m, dropout=d,\n",
      "                    fold=f, split=s, partition=partitions[1])))\n",
      "                # v157 is the third position in the list\n",
      "                macro_aves[si, mi, di, fi] = np.mean(res['macro_average'][2][1])\n",
      "                these_quals = res['macro_average'][2][0]\n",
      "                qualitywise[si, mi, di, :, 0, fi] = np.array(\n",
      "                    [res['macro_average'][2][1][these_quals.index(q)] for q in quals])\n",
      "                qualitywise[si, mi, di, :, 1, fi] = np.array(\n",
      "                    [res['macro_average'][2][2][these_quals.index(q)] for q in quals])\n",
      "                scores, supports = [np.array(_) for _ in res['score_annotations']]\n",
      "                scalar = supports.sum(axis=0)\n",
      "                scalar[scalar == 0] = 1.0\n",
      "                micro_recall[si, mi, di, fi, :] = (supports * scores).sum(axis=0) / scalar"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Collect Comparison Scores (TMC)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "macro_aves2 = np.zeros([2, 5])\n",
      "micro_recall2 = np.zeros([2, 5, 8])\n",
      "qualitywise2 = np.zeros([2, 14, 2, 5])\n",
      "for si, s in enumerate(splits[::2]):\n",
      "    for fi, f in enumerate(folds):\n",
      "        res = json.load(open(res_fmt.format(\n",
      "            basedir=basedir, model='tmc', dropout='band-4',\n",
      "            fold=f, split=s, partition=partitions[1])))\n",
      "        # v157 is the third position in the list\n",
      "        macro_aves2[si, fi] = np.mean(res['macro_average'][2][1])\n",
      "        these_quals = res['macro_average'][2][0]\n",
      "        qualitywise2[si, :, 0, fi] = np.array(\n",
      "            [res['macro_average'][2][1][these_quals.index(q)] for q in quals])\n",
      "        qualitywise2[si, :, 1, fi] = np.array(\n",
      "            [res['macro_average'][2][2][these_quals.index(q)] for q in quals])\n",
      "        scores, supports = [np.array(_) for _ in res['score_annotations']]\n",
      "        scalar = supports.sum(axis=0)\n",
      "        scalar[scalar == 0] = 1.0\n",
      "        micro_recall2[si, fi, :] = (supports * scores).sum(axis=0) / scalar"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Overall Micro-recall"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Sweep across models, dropout values, metrics; avereaged over folds."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for si, s in enumerate(splits):\n",
      "    for mi, m in enumerate(models):\n",
      "        print tabulate.tabulate([[d] + r.tolist() \n",
      "                                 for d, r in zip(dropout, micro_recall[si, mi].mean(axis=1))], \n",
      "                                headers=[\"{0}-{1}\".format(s, m)] + metrics) + \"\\n\"\n",
      "print tabulate.tabulate([[s] +  micro_recall2[si].mean(axis=0).tolist() \n",
      "                         for si, s in enumerate(splits[::2])], \n",
      "                        headers=metrics) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  train-L    triads      root    v157_strict     mirex    tetrads    sevenths    thirds    majmin\n",
        "---------  --------  --------  -------------  --------  ---------  ----------  --------  --------\n",
        "    0      0.908672  0.924946       0.860016  0.91402    0.860016    0.860072  0.917702  0.909678\n",
        "    0.125  0.870644  0.90179        0.779818  0.878538   0.779818    0.779248  0.889468  0.871788\n",
        "    0.25   0.838245  0.881085       0.726646  0.84898    0.726646    0.727702  0.86367   0.840543\n",
        "    0.5    0.79156   0.849139       0.657671  0.807897   0.657671    0.664147  0.826154  0.797039\n",
        "\n",
        "  train-XL    triads      root    v157_strict     mirex    tetrads    sevenths    thirds    majmin\n",
        "----------  --------  --------  -------------  --------  ---------  ----------  --------  --------\n",
        "     0      0.923635  0.935253       0.89031   0.927683   0.89031     0.890617  0.93      0.924428\n",
        "     0.125  0.889927  0.914462       0.821672  0.89623    0.821672    0.821383  0.904921  0.890782\n",
        "     0.25   0.850381  0.888757       0.737407  0.860974   0.737407    0.738504  0.873367  0.852734\n",
        "     0.5    0.797154  0.85409        0.663235  0.811761   0.663235    0.668252  0.832927  0.801446\n",
        "\n",
        "  train-XXL    triads      root    v157_strict     mirex    tetrads    sevenths    thirds    majmin\n",
        "-----------  --------  --------  -------------  --------  ---------  ----------  --------  --------\n",
        "      0      0.946185  0.952818       0.929731  0.948735   0.929731    0.929954  0.949843  0.94656\n",
        "      0.125  0.899422  0.920913       0.838593  0.90478    0.838593    0.837429  0.913256  0.899712\n",
        "      0.25   0.870122  0.904106       0.783337  0.877693   0.783337    0.782775  0.892111  0.870989\n",
        "      0.5    0.804323  0.85733        0.678286  0.818399   0.678286    0.681975  0.837384  0.808041\n",
        "\n",
        "  valid-L    triads      root    v157_strict     mirex    tetrads    sevenths    thirds    majmin\n",
        "---------  --------  --------  -------------  --------  ---------  ----------  --------  --------\n",
        "    0      0.797034  0.848686       0.665595  0.812807   0.665595    0.67834   0.816644  0.807394\n",
        "    0.125  0.795713  0.850992       0.659796  0.810454   0.659796    0.668586  0.821369  0.803413\n",
        "    0.25   0.794506  0.853177       0.658546  0.809553   0.658546    0.665421  0.824037  0.80119\n",
        "    0.5    0.779283  0.844601       0.639024  0.796472   0.639024    0.646761  0.816717  0.786597\n",
        "\n",
        "  valid-XL    triads      root    v157_strict     mirex    tetrads    sevenths    thirds    majmin\n",
        "----------  --------  --------  -------------  --------  ---------  ----------  --------  --------\n",
        "     0      0.797276  0.848117       0.67103   0.812029   0.67103     0.684136  0.814823  0.807556\n",
        "     0.125  0.801415  0.852997       0.674284  0.815808   0.674284    0.684303  0.824525  0.80968\n",
        "     0.25   0.798156  0.853322       0.655099  0.814707   0.655099    0.662288  0.825028  0.805115\n",
        "     0.5    0.778096  0.844768       0.638747  0.794666   0.638747    0.645435  0.817223  0.784295\n",
        "\n",
        "  valid-XXL    triads      root    v157_strict     mirex    tetrads    sevenths    thirds    majmin\n",
        "-----------  --------  --------  -------------  --------  ---------  ----------  --------  --------\n",
        "      0      0.797807  0.850298       0.665685  0.81265    0.665685    0.680161  0.813848  0.808736\n",
        "      0.125  0.798004  0.849563       0.66787   0.812531   0.66787     0.677728  0.821038  0.806166\n",
        "      0.25   0.797028  0.854486       0.665544  0.811166   0.665544    0.673606  0.826161  0.804204\n",
        "      0.5    0.780426  0.842455       0.643406  0.795862   0.643406    0.649831  0.816535  0.786866\n",
        "\n",
        "  test-L    triads      root    v157_strict     mirex    tetrads    sevenths    thirds    majmin\n",
        "--------  --------  --------  -------------  --------  ---------  ----------  --------  --------\n",
        "   0      0.793919  0.844243       0.658275  0.810159   0.658275    0.67248   0.813544  0.804129\n",
        "   0.125  0.795051  0.846538       0.651616  0.810904   0.651616    0.661585  0.820332  0.802795\n",
        "   0.25   0.788176  0.844499       0.65088   0.803854   0.65088     0.659234  0.817515  0.795006\n",
        "   0.5    0.776185  0.837168       0.635827  0.793624   0.635827    0.644197  0.811516  0.783172\n",
        "\n",
        "  test-XL    triads      root    v157_strict     mirex    tetrads    sevenths    thirds    majmin\n",
        "---------  --------  --------  -------------  --------  ---------  ----------  --------  --------\n",
        "    0      0.793943  0.843163       0.6589    0.809817   0.6589      0.673568  0.812198  0.804201\n",
        "    0.125  0.799507  0.849345       0.667284  0.814513   0.667284    0.678771  0.822708  0.807711\n",
        "    0.25   0.794965  0.847876       0.649279  0.811366   0.649279    0.657968  0.821459  0.802251\n",
        "    0.5    0.777307  0.840098       0.635064  0.793996   0.635064    0.642967  0.814672  0.783643\n",
        "\n",
        "  test-XXL    triads      root    v157_strict     mirex    tetrads    sevenths    thirds    majmin\n",
        "----------  --------  --------  -------------  --------  ---------  ----------  --------  --------\n",
        "     0      0.796859  0.846251       0.658262  0.812965   0.658262    0.674131  0.813591  0.807957\n",
        "     0.125  0.799271  0.84771        0.663314  0.813989   0.663314    0.674461  0.821452  0.807504\n",
        "     0.25   0.79471   0.8497         0.659239  0.809175   0.659239    0.668598  0.82406   0.802015\n",
        "     0.5    0.776776  0.836931       0.639215  0.794124   0.639215    0.646801  0.812131  0.783026\n",
        "\n",
        "         triads      root    v157_strict     mirex    tetrads    sevenths    thirds    majmin\n",
        "-----  --------  --------  -------------  --------  ---------  ----------  --------  --------\n",
        "train  0.805265  0.852874       0.676308  0.820528   0.676308    0.682282  0.826133  0.810925\n",
        "test   0.796956  0.847485       0.659215  0.814706   0.659215    0.670416  0.819659  0.805673\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Observations:\n",
      "* Deep net models overfit the training set like crazy; dropout brings this down, but the ROI appears marginal.\n",
      "* The biggest deep net is sufficiently complex to overfit the training data. This serves as a good upper bound on complexity.\n",
      "* A little dropout (0.125, 0.25) has a slight positive effect on training; too much dropout (0.5), on the other hand, is definitely a bad thing, and seems to destabilize estimations.\n",
      "* The best deep net appears essentially equivalent to the state of the art comparison system; XL-0.125 just *barely* eclipses the SotA system in every metric but 'mirex', XXL-0.125 is on its heels.\n",
      "* The different metrics indicate that confusions at the strict level are predominantly musically related, i.e. descending order from root, thirds, triads, sevenths, tetrads. "
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Quality-wise Macro-recall"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Tabulate quality-wise macro-recall, i.e. average performance across transposed chord qualities."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for si, s in enumerate(splits):\n",
      "    print tabulate.tabulate([[m] + r.tolist() \n",
      "                             for m, r in zip(models, macro_aves[si].mean(axis=-1))], \n",
      "                            headers=[s]+dropout) + \"\\n\"\n",
      "print tabulate.tabulate([['tmc'] +  macro_aves2.mean(axis=-1).tolist()], headers=splits[::2]) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "train         0.0     0.125      0.25       0.5\n",
        "-------  --------  --------  --------  --------\n",
        "L        0.885847  0.826335  0.740316  0.583849\n",
        "XL       0.904864  0.856898  0.765205  0.6147\n",
        "XXL      0.9421    0.883839  0.823243  0.645914\n",
        "\n",
        "valid         0.0     0.125      0.25       0.5\n",
        "-------  --------  --------  --------  --------\n",
        "L        0.448241  0.532196  0.548604  0.529669\n",
        "XL       0.440974  0.509679  0.546217  0.54786\n",
        "XXL      0.412469  0.507723  0.54302   0.5541\n",
        "\n",
        "test         0.0     0.125      0.25       0.5\n",
        "------  --------  --------  --------  --------\n",
        "L       0.430559  0.502933  0.52401   0.513465\n",
        "XL      0.417379  0.488744  0.528092  0.525258\n",
        "XXL     0.393497  0.482518  0.512694  0.525689\n",
        "\n",
        "        train     test\n",
        "---  --------  -------\n",
        "tmc  0.624761  0.45464\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Quality-wise Macro-recall -- Individual Qualities"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here, rather than averaging scores over qualities, the data are broken out by individual chord qualities."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "qualitywise_ave = qualitywise.mean(axis=-1)\n",
      "qualitywise2_ave = qualitywise2.mean(axis=-1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for si, s in enumerate(splits):\n",
      "    for mi, m in enumerate(models):\n",
      "        qwise = qualitywise_ave[si, mi].transpose(1, 0, 2)\n",
      "        supports = qwise[:, :, 1].mean(axis=1) / 60.0\n",
      "        print tabulate.tabulate([[q, t] + r.tolist() \n",
      "                                 for q, t, r in zip(quals, supports, qwise[:, :, 0])], \n",
      "                                headers=[\"{0}-{1}\".format(s, m), 'support'] + dropout, floatfmt=\".4f\") + \"\\n\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "train-L      support     0.0    0.125    0.25     0.5\n",
        "---------  ---------  ------  -------  ------  ------\n",
        "C:maj      1345.4895  0.8581   0.7641  0.7293  0.6851\n",
        "C:min       360.1782  0.8319   0.7686  0.7455  0.6177\n",
        "C:7         231.0837  0.8350   0.7761  0.6686  0.5836\n",
        "C:min7      218.2594  0.8707   0.7770  0.6300  0.5851\n",
        "N           141.6480  0.9563   0.9176  0.8675  0.7917\n",
        "C:maj7       81.8933  0.8929   0.8471  0.8059  0.7415\n",
        "C:maj6       26.6943  0.8486   0.7581  0.6663  0.4268\n",
        "C:sus4       27.9709  0.8127   0.7682  0.6800  0.4632\n",
        "C:sus2        8.2460  0.8703   0.7877  0.6530  0.5063\n",
        "C:aug         4.5747  0.9445   0.9303  0.8597  0.6210\n",
        "C:dim         6.6839  0.8950   0.8197  0.6578  0.4455\n",
        "C:min6        5.3941  0.9092   0.8810  0.7674  0.5057\n",
        "C:hdim7       3.9334  0.9441   0.9268  0.8789  0.8022\n",
        "C:dim7        2.0199  0.9327   0.8463  0.7545  0.3984\n",
        "\n",
        "train-XL      support     0.0    0.125    0.25     0.5\n",
        "----------  ---------  ------  -------  ------  ------\n",
        "C:maj       1345.4895  0.8891   0.8151  0.7246  0.6784\n",
        "C:min        360.1782  0.8771   0.8093  0.7222  0.6386\n",
        "C:7          231.0837  0.8709   0.7970  0.7251  0.5904\n",
        "C:min7       218.2594  0.8876   0.8184  0.7371  0.6036\n",
        "N            141.6480  0.9707   0.9367  0.8885  0.8162\n",
        "C:maj7        81.8933  0.9023   0.8566  0.8178  0.7746\n",
        "C:maj6        26.6943  0.8674   0.7989  0.6689  0.4313\n",
        "C:sus4        27.9709  0.8527   0.7992  0.6697  0.5479\n",
        "C:sus2         8.2460  0.8792   0.8570  0.7227  0.5235\n",
        "C:aug          4.5747  0.9501   0.9408  0.8676  0.6939\n",
        "C:dim          6.6839  0.9124   0.8432  0.6999  0.4959\n",
        "C:min6         5.3941  0.9236   0.8826  0.7871  0.5669\n",
        "C:hdim7        3.9334  0.9558   0.9454  0.9051  0.8171\n",
        "C:dim7         2.0199  0.9292   0.8966  0.7766  0.4276\n",
        "\n",
        "train-XXL      support     0.0    0.125    0.25     0.5\n",
        "-----------  ---------  ------  -------  ------  ------\n",
        "C:maj        1345.4895  0.9256   0.8217  0.7780  0.6932\n",
        "C:min         360.1782  0.9195   0.8380  0.7873  0.6317\n",
        "C:7           231.0837  0.9296   0.8250  0.7260  0.6131\n",
        "C:min7        218.2594  0.9378   0.8441  0.7531  0.6423\n",
        "N             141.6480  0.9788   0.9602  0.9149  0.8426\n",
        "C:maj7         81.8933  0.9427   0.8990  0.8496  0.7422\n",
        "C:maj6         26.6943  0.9106   0.8488  0.7589  0.5267\n",
        "C:sus4         27.9709  0.9053   0.8512  0.7844  0.5746\n",
        "C:sus2          8.2460  0.9295   0.8857  0.8142  0.5517\n",
        "C:aug           4.5747  0.9651   0.9486  0.9229  0.7537\n",
        "C:dim           6.6839  0.9522   0.8797  0.7751  0.4798\n",
        "C:min6          5.3941  0.9514   0.9025  0.8675  0.6432\n",
        "C:hdim7         3.9334  0.9772   0.9544  0.9279  0.8544\n",
        "C:dim7          2.0199  0.9641   0.9149  0.8655  0.4936\n",
        "\n",
        "valid-L      support     0.0    0.125    0.25     0.5\n",
        "---------  ---------  ------  -------  ------  ------\n",
        "C:maj       244.4654  0.7609   0.7006  0.6975  0.6744\n",
        "C:min        62.8782  0.5881   0.6300  0.6709  0.6184\n",
        "C:7          41.4449  0.4570   0.5774  0.5392  0.5444\n",
        "C:min7       37.5511  0.5340   0.5624  0.5045  0.5592\n",
        "N            25.1497  0.7046   0.7518  0.7600  0.7337\n",
        "C:maj7       11.3449  0.6649   0.7610  0.7748  0.7524\n",
        "C:maj6        3.9975  0.3096   0.4017  0.4602  0.4081\n",
        "C:sus4        5.2851  0.2326   0.3460  0.4075  0.3452\n",
        "C:sus2        1.4542  0.1958   0.3848  0.4594  0.4827\n",
        "C:aug         0.5074  0.4022   0.5827  0.5615  0.4684\n",
        "C:dim         0.8184  0.3936   0.4453  0.3787  0.3529\n",
        "C:min6        0.8922  0.3346   0.4415  0.6493  0.6188\n",
        "C:hdim7       0.6688  0.4757   0.5969  0.6075  0.6238\n",
        "C:dim7        0.2399  0.2218   0.2687  0.2096  0.2328\n",
        "\n",
        "valid-XL      support     0.0    0.125    0.25     0.5\n",
        "----------  ---------  ------  -------  ------  ------\n",
        "C:maj        244.4654  0.7725   0.7405  0.6829  0.6650\n",
        "C:min         62.8782  0.6145   0.6299  0.6303  0.6310\n",
        "C:7           41.4449  0.4349   0.5173  0.5802  0.5395\n",
        "C:min7        37.5511  0.4906   0.5501  0.5888  0.5563\n",
        "N             25.1497  0.7226   0.7468  0.7611  0.7568\n",
        "C:maj7        11.3449  0.6249   0.7240  0.7630  0.7772\n",
        "C:maj6         3.9975  0.2833   0.3659  0.4341  0.4046\n",
        "C:sus4         5.2851  0.2433   0.3238  0.3728  0.3977\n",
        "C:sus2         1.4542  0.1786   0.3502  0.4735  0.5388\n",
        "C:aug          0.5074  0.4562   0.5749  0.6072  0.5249\n",
        "C:dim          0.8184  0.3941   0.3365  0.4042  0.3504\n",
        "C:min6         0.8922  0.3552   0.5241  0.5789  0.6730\n",
        "C:hdim7        0.6688  0.4265   0.5358  0.6433  0.6447\n",
        "C:dim7         0.2399  0.1765   0.2156  0.1269  0.2103\n",
        "\n",
        "valid-XXL      support     0.0    0.125    0.25     0.5\n",
        "-----------  ---------  ------  -------  ------  ------\n",
        "C:maj         244.4654  0.7896   0.7307  0.7158  0.6733\n",
        "C:min          62.8782  0.5640   0.6431  0.6634  0.6089\n",
        "C:7            41.4449  0.4058   0.5063  0.4973  0.5402\n",
        "C:min7         37.5511  0.5075   0.5337  0.5393  0.5863\n",
        "N              25.1497  0.6794   0.7546  0.7590  0.7732\n",
        "C:maj7         11.3449  0.5974   0.7234  0.7573  0.7477\n",
        "C:maj6          3.9975  0.2036   0.3545  0.4252  0.4645\n",
        "C:sus4          5.2851  0.2024   0.3380  0.3818  0.3887\n",
        "C:sus2          1.4542  0.1709   0.3314  0.4053  0.5263\n",
        "C:aug           0.5074  0.3870   0.5294  0.5288  0.5499\n",
        "C:dim           0.8184  0.3532   0.4798  0.3437  0.3195\n",
        "C:min6          0.8922  0.2484   0.4721  0.5854  0.6651\n",
        "C:hdim7         0.6688  0.4625   0.5039  0.6744  0.6588\n",
        "C:dim7          0.2399  0.2027   0.2073  0.3256  0.2549\n",
        "\n",
        "test-L      support     0.0    0.125    0.25     0.5\n",
        "--------  ---------  ------  -------  ------  ------\n",
        "C:maj      397.4887  0.7571   0.6968  0.6928  0.6724\n",
        "C:min      105.7641  0.5750   0.6046  0.6545  0.5901\n",
        "C:7         68.1321  0.4418   0.5628  0.5236  0.5395\n",
        "C:min7      63.9526  0.5234   0.5466  0.4986  0.5658\n",
        "N           41.6994  0.7321   0.7753  0.7792  0.7527\n",
        "C:maj7      23.3095  0.6302   0.7126  0.7329  0.7055\n",
        "C:maj6       7.6729  0.2213   0.3316  0.3883  0.3680\n",
        "C:sus4       8.3140  0.2347   0.3671  0.4129  0.3766\n",
        "C:sus2       2.4250  0.1900   0.3094  0.3562  0.4174\n",
        "C:aug        1.2705  0.3961   0.5163  0.5672  0.4957\n",
        "C:dim        1.8756  0.4377   0.4762  0.4443  0.3612\n",
        "C:min6       1.5716  0.2662   0.3734  0.4397  0.4993\n",
        "C:hdim7      1.1506  0.4387   0.5894  0.6120  0.6277\n",
        "C:dim7       0.5650  0.1836   0.1790  0.2340  0.2166\n",
        "\n",
        "test-XL      support     0.0    0.125    0.25     0.5\n",
        "---------  ---------  ------  -------  ------  ------\n",
        "C:maj       397.4887  0.7669   0.7390  0.6776  0.6645\n",
        "C:min       105.7641  0.5868   0.6105  0.6085  0.6001\n",
        "C:7          68.1321  0.4315   0.5183  0.5783  0.5362\n",
        "C:min7       63.9526  0.4840   0.5263  0.5954  0.5593\n",
        "N            41.6994  0.7408   0.7679  0.7875  0.7772\n",
        "C:maj7       23.3095  0.5802   0.6780  0.7268  0.7410\n",
        "C:maj6        7.6729  0.1929   0.2908  0.3847  0.3540\n",
        "C:sus4        8.3140  0.2380   0.3369  0.3811  0.4231\n",
        "C:sus2        2.4250  0.1921   0.3216  0.3698  0.3995\n",
        "C:aug         1.2705  0.3730   0.5078  0.5346  0.5521\n",
        "C:dim         1.8756  0.4167   0.4105  0.4140  0.3955\n",
        "C:min6        1.5716  0.2552   0.3870  0.4505  0.5076\n",
        "C:hdim7       1.1506  0.3840   0.5688  0.6659  0.6140\n",
        "C:dim7        0.5650  0.2012   0.1790  0.2186  0.2296\n",
        "\n",
        "test-XXL      support     0.0    0.125    0.25     0.5\n",
        "----------  ---------  ------  -------  ------  ------\n",
        "C:maj        397.4887  0.7863   0.7274  0.7146  0.6730\n",
        "C:min        105.7641  0.5631   0.6262  0.6348  0.5882\n",
        "C:7           68.1321  0.3915   0.4982  0.4996  0.5319\n",
        "C:min7        63.9526  0.4850   0.5223  0.5238  0.5832\n",
        "N             41.6994  0.6985   0.7839  0.7832  0.7919\n",
        "C:maj7        23.3095  0.5609   0.7080  0.7201  0.7021\n",
        "C:maj6         7.6729  0.1444   0.3167  0.3668  0.3936\n",
        "C:sus4         8.3140  0.1959   0.3352  0.3918  0.4225\n",
        "C:sus2         2.4250  0.1221   0.3420  0.3289  0.4225\n",
        "C:aug          1.2705  0.3450   0.4388  0.5582  0.5489\n",
        "C:dim          1.8756  0.4554   0.5158  0.4106  0.3813\n",
        "C:min6         1.5716  0.1786   0.3217  0.3941  0.4867\n",
        "C:hdim7        1.1506  0.4272   0.4447  0.6092  0.6380\n",
        "C:dim7         0.5650  0.1552   0.1743  0.2419  0.1958\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for si, s in enumerate(splits[::2]):\n",
      "    qwise = qualitywise2_ave[si]\n",
      "    supports = qwise[:, 1] / 60.0\n",
      "    print tabulate.tabulate([[q, t, r] \n",
      "                             for q, t, r in zip(quals, supports, qwise[:, 0])], \n",
      "                            headers=[\"{0}-{1}\".format(s, 'tmc'), 'support', 'qw-recall'], \n",
      "                            floatfmt=\".4f\") + \"\\n\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "train-tmc      support    qw-recall\n",
        "-----------  ---------  -----------\n",
        "C:maj         1589.955        0.723\n",
        "C:min          423.056        0.664\n",
        "C:7            272.529        0.614\n",
        "C:min7         255.811        0.579\n",
        "N              166.798        0.601\n",
        "C:maj7          93.238        0.693\n",
        "C:maj6          30.692        0.440\n",
        "C:sus4          33.256        0.439\n",
        "C:sus2           9.700        0.505\n",
        "C:aug            5.082        0.715\n",
        "C:dim            7.502        0.696\n",
        "C:min6           6.286        0.536\n",
        "C:hdim7          4.602        0.751\n",
        "C:dim7           2.260        0.789\n",
        "\n",
        "test-tmc      support    qw-recall\n",
        "----------  ---------  -----------\n",
        "C:maj         397.489        0.720\n",
        "C:min         105.764        0.647\n",
        "C:7            68.132        0.596\n",
        "C:min7         63.953        0.538\n",
        "N              41.699        0.588\n",
        "C:maj7         23.310        0.659\n",
        "C:maj6          7.673        0.303\n",
        "C:sus4          8.314        0.389\n",
        "C:sus2          2.425        0.199\n",
        "C:aug           1.271        0.375\n",
        "C:dim           1.876        0.515\n",
        "C:min6          1.572        0.313\n",
        "C:hdim7         1.151        0.459\n",
        "C:dim7          0.565        0.064\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Observations:\n",
      "* There are **sharp** distribution effects in the validation and test splits. Performance for chord qualities is typically quite high.\n",
      "* Dominant 7's seem relatively low; this is likely a result of V vs V7 confusions, but the annotations don't provide this information to validate the hypothesis.\n",
      "* The only chord quality to *decrease* with dropout is ```major```, indicating that in the absence of dropout, the class is over-predicted. This makes sense, as it is the majority class. \n",
      "* XXL-0.25 yields near identical micro statistics to TMC, but achieves a significant increase in QW macro-recall, 0.5127 to 0.4546 (0.0581).\n",
      "* TMC does noticeably better on ```C:7```; deep nets do noticeably better on ```N```. \n",
      "* It seems impossible to determine a global \"best\" model, as dropout appears to only move the decision boundaries between classes. Therefore the representational power of the model doesn't really seems to change, simply where the boundaries between classes fall, and thus model selection may ultimately be a function of use-case. Is it better to have a model that safely predicts simpler chords, i.e. major, most of the time? Or to have a model that makes use of a wider vocabulary of chords?"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Corpus Effects"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Returning to XL-0.125, pull in all estimations from all test splits and associate tracks with the corpus to which they belong."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "refs = util.load_jamset(\"{basedir}/references_strict.jamset\".format(basedir=basedir))\n",
      "est_fmt = res_fmt = \"{basedir}/estimations/{model}/{dropout}/{fold}/{split}/best.jamset\"\n",
      "params = dict(\n",
      "    basedir=basedir, model=models[1], \n",
      "    dropout=dropout[1], split=splits[2])\n",
      "ests = dict()\n",
      "for f in folds:\n",
      "    ests.update(**util.load_jamset(est_fmt.format(fold=f, **params)))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "keys = ests.keys()\n",
      "est_annots = [ests[k].chord[0] for k in keys]\n",
      "ref_annots = [refs[k].chord[0] for k in keys]\n",
      "corpus = [a.annotation_metadata.corpus for a in ref_annots]\n",
      "num_annots = len(ref_annots)\n",
      "corpus_set = list(set(corpus))\n",
      "corpus_idx = np.array([corpus_set.index(c) for c in corpus])\n",
      "colors = np.zeros([num_annots, 3]) + 0.1\n",
      "colors[np.arange(num_annots), corpus_idx] = 0.9"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "annot_scores, annot_supports = E.score_annotations(ref_annots, est_annots, metrics)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for idx, c in enumerate(corpus_set):\n",
      "    bidx = np.equal(corpus_idx, idx)\n",
      "    corp_scores_macro = annot_scores[bidx].mean(axis=0)\n",
      "    corp_scores_micro = (annot_supports[bidx] * annot_scores[bidx]).sum(axis=0) \n",
      "    corp_scores_micro /= annot_supports[bidx].sum(axis=0)\n",
      "    print \"{0:20}\\tmacro   micro\\n\".format(c) + '-'*40\n",
      "    for mi, (m, s1, s2) in enumerate(zip(metrics, corp_scores_macro, corp_scores_micro)):\n",
      "        print \"({0}) {1:16}:\\t{2:.4f}\\t{3:.4f}\".format(mi, m, s1, s2)\n",
      "    print \"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Isophonics          \tmacro   micro\n",
        "----------------------------------------\n",
        "(0) triads          :\t0.8354\t0.8345\n",
        "(1) root            :\t0.8686\t0.8680\n",
        "(2) v157_strict     :\t0.6890\t0.6851\n",
        "(3) mirex           :\t0.8464\t0.8450\n",
        "(4) tetrads         :\t0.6890\t0.6851\n",
        "(5) sevenths        :\t0.7012\t0.6973\n",
        "(6) thirds          :\t0.8490\t0.8480\n",
        "(7) majmin          :\t0.8441\t0.8433\n",
        "\n",
        "MARL-Chords         \tmacro   micro\n",
        "----------------------------------------\n",
        "(0) triads          :\t0.8124\t0.8096\n",
        "(1) root            :\t0.8674\t0.8657\n",
        "(2) v157_strict     :\t0.6830\t0.6742\n",
        "(3) mirex           :\t0.8302\t0.8270\n",
        "(4) tetrads         :\t0.6830\t0.6742\n",
        "(5) sevenths        :\t0.6982\t0.6888\n",
        "(6) thirds          :\t0.8481\t0.8453\n",
        "(7) majmin          :\t0.8240\t0.8203\n",
        "\n",
        "Billboard-Chords    \tmacro   micro\n",
        "----------------------------------------\n",
        "(0) triads          :\t0.7890\t0.7868\n",
        "(1) root            :\t0.8351\t0.8376\n",
        "(2) v157_strict     :\t0.6607\t0.6601\n",
        "(3) mirex           :\t0.8048\t0.8017\n",
        "(4) tetrads         :\t0.6607\t0.6601\n",
        "(5) sevenths        :\t0.6702\t0.6701\n",
        "(6) thirds          :\t0.8080\t0.8066\n",
        "(7) majmin          :\t0.7953\t0.7939\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Observations:\n",
      "* Isophonics exhibits the best performance. Two possible explanations: the content is the easiest because it comes from (mostly) one artist; the annotation process was the most rigorous, and thus might contain the most consistent labeling.\n",
      "* MARL-chords is in the middle. Roots and thirds are equal with Isophonics, but triads (aug / dims) have some issues. Could be a combination of how the annotators use them and the content.\n",
      "* Worst performance on Billboard; necessary to consider that this dataset has the highest number of contributors. However, it also has the most diverse content."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Enter, the Rock Corpus"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Much can and has been said about the consistency, and thus quality, of the annotations used for development and evaluation of chord estimation systems. The majority of human-provided chord annotations are often singular, either being performed by one person or as the result of a review process to resolve disagreements.\n",
      "\n",
      "The notion of annotator disagreements is an interesting one, because there are two reasons why this might occur. The first is simply a matter of human error, typos and the like. The second, and far more interesting cause, is that there is some ambiguity in the musical content, leading to different acceptable annotations.\n",
      "\n",
      "Since most dataset curation efforts have made an explicit effort to iron out these discrepancies, it isn't possible to explore any such instances in the data used so far. The Rock Corpus, however, does afford this opportunity. The collection contains 200 popular songs from the last several decades, each annotated by two music experts: one, a pianist, and the other, a guitarist. This background adds an interesting dimension to the inquiry, when considering points of aggrement or disagreement between annotators and algorithmic methods."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Consolidate the different RC-Jams into a jamset for convenience\n",
      "import marl.fileutils as futil\n",
      "rc = dict()\n",
      "for f in glob.glob(\"/Volumes/megatron/dl4mir/rock_corpus/references/TR*.jams\"):\n",
      "    key = futil.filebase(f)\n",
      "    rc[key] = pyjams.load(f)\n",
      "\n",
      "util.save_jamset(rc, \"/Volumes/megatron/dl4mir/rock_corpus/references.jamset\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load jamsets into mem\n",
      "basedir = \"/Volumes/megatron/dl4mir/rock_corpus\"\n",
      "refs = util.load_jamset(\"{basedir}/references.jamset\".format(basedir=basedir))\n",
      "est_fmt = res_fmt = \"{basedir}/estimations/{model}/{dropout}/{fold}/{split}/best.jamset\"\n",
      "params = dict(\n",
      "    basedir=basedir, model=models[1], \n",
      "    dropout=dropout[1], split='stash')\n",
      "ests = [util.load_jamset(est_fmt.format(fold=f, **params)) for f in folds]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Back-out annotations into different collections\n",
      "keys = ests[0].keys()\n",
      "ref_annots_dt = [refs[k].chord[0] for k in keys]\n",
      "ref_annots_tdc = [refs[k].chord[1] for k in keys]\n",
      "est_annots = [[e[k].chord[0] for k in keys] for e in ests]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Human vs Human\n",
      "humans = [ref_annots_dt, ref_annots_tdc]\n",
      "micro_recall = np.zeros([2, 8])\n",
      "for i, (a, b) in enumerate(zip(humans, humans[::-1])):\n",
      "    scores, supports = E.score_annotations(a, b, metrics)\n",
      "    scalar = supports.sum(axis=0)\n",
      "    scalar[scalar == 0] = 1.0\n",
      "    micro_recall[i] = (supports * scores).sum(axis=0) / scalar\n",
      "print tabulate.tabulate(\n",
      "    [[m] + r.tolist() for m, r in zip(['dt-tdc', 'tdc-dt'], micro_recall)], \n",
      "    headers=[''] + metrics, floatfmt=\".4f\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "          triads    root    v157_strict    mirex    tetrads    sevenths    thirds    majmin\n",
        "------  --------  ------  -------------  -------  ---------  ----------  --------  --------\n",
        "dt-tdc    0.8986  0.9329         0.8355   0.9180     0.8355      0.8380    0.9042    0.9008\n",
        "tdc-dt    0.9117  0.9465         0.8514   0.9168     0.8477      0.8537    0.9174    0.9176\n"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Observations:\n",
      "* Experts don't agree, even after error-checking.\n",
      "* There is asymmetry in chord comparisons! Depending on who gets used as the reference, a comparison may match better or worse.\n",
      "* DT's vocabulary is a superset of TdC's, hence the consistent difference. \n",
      "* Even the MIREX score isn't perfect, which is surprising. Typically, one would think that the difficulty in naming a chord isn't identifying the contributing pitches, but spelling the name in the context of the piece. However, even humans aren't sure which pitches matter."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Human vs Machine(s)\n",
      "#                  ref,              track, metric, fold\n",
      "recall = np.zeros([  2, len(ref_annots_dt),      8,    5])\n",
      "micro_recall = np.zeros([2, 8, 5])\n",
      "for ri, r in enumerate([ref_annots_dt, ref_annots_tdc]):\n",
      "    for fi, e in enumerate(est_annots):\n",
      "        scores, supports = E.score_annotations(r, e, metrics)\n",
      "        recall[ri, :, :, fi] = scores\n",
      "        scalar = supports.sum(axis=0)\n",
      "        scalar[scalar == 0] = 1.0\n",
      "        micro_recall[ri, :, fi] = (supports * scores).sum(axis=0) / scalar\n",
      "\n",
      "print tabulate.tabulate(\n",
      "    [[m] + r.tolist() for m, r in zip(['dt', 'tdc'], micro_recall.mean(axis=-1))],\n",
      "    headers=[''] + metrics, floatfmt=\".4f\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "       triads    root    v157_strict    mirex    tetrads    sevenths    thirds    majmin\n",
        "---  --------  ------  -------------  -------  ---------  ----------  --------  --------\n",
        "dt     0.7051  0.7816         0.5625   0.7180     0.5625      0.5653    0.7314    0.7084\n",
        "tdc    0.7182  0.7939         0.5794   0.7314     0.5786      0.5822    0.7444    0.7228\n"
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "recall_ave = recall.mean(axis=-1)\n",
      "recall_maxor = recall_ave.max(axis=0)\n",
      "affinity = np.array([np.bincount(_) for _ in recall_ave.argmax(axis=0).T])\n",
      "micro_recall_maxor = (supports * recall_maxor).sum(axis=0) / scalar\n",
      "print tabulate.tabulate([['dt | tdc'] + micro_recall_maxor.tolist()],\n",
      "                        headers=[''] + metrics, floatfmt=\".4f\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "            triads    root    v157_strict    mirex    tetrads    sevenths    thirds    majmin\n",
        "--------  --------  ------  -------------  -------  ---------  ----------  --------  --------\n",
        "dt | tdc    0.7306  0.8010         0.6003   0.7431     0.5998      0.6032    0.7569    0.7348\n"
       ]
      }
     ],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}